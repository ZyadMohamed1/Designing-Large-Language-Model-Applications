{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f8d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce61be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original numbers: [2.3888888, 0, 34.444, 123486.0, -1223.4566]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Original numbers in full precision\n",
    "numbers = [2.3888888, 0, 34.444, 12.3486e4, -1223.4566]\n",
    "print(\"Original numbers:\", numbers)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28eb408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_and_compute(numbers, dtype_name):\n",
    "    print(f\"\\n{dtype_name.upper()} Results:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if dtype_name == \"float32\":\n",
    "        quantized = [np.float32(x) for x in numbers]\n",
    "    elif dtype_name == \"float16\":\n",
    "        quantized = [np.float16(x) for x in numbers]\n",
    "    elif dtype_name == \"bfloat16\":\n",
    "        # Simulate bfloat16 by truncating mantissa (keep sign + 8 exp + 7 mantissa bits)\n",
    "        quantized = []\n",
    "        for x in numbers:\n",
    "            if x == 0:\n",
    "                quantized.append(0.0)\n",
    "            else:\n",
    "                # Convert to float32 first, then simulate bfloat16 precision loss\n",
    "                f32 = np.float32(x)\n",
    "                # Simple bfloat16 simulation - round to fewer significant digits\n",
    "                if abs(f32) >= 1:\n",
    "                    # Keep ~3-4 significant digits for bfloat16\n",
    "                    rounded = round(f32, max(0, 3 - len(str(int(abs(f32))))))\n",
    "                else:\n",
    "                    rounded = round(f32, 4)\n",
    "                quantized.append(rounded)\n",
    "    elif dtype_name == \"int8\":\n",
    "        # Scale and clip to int8 range [-128, 127]\n",
    "        # Using simple scaling - find max absolute value for scaling factor\n",
    "        max_val = max(abs(x) for x in numbers if x != 0)\n",
    "        scale = 127 / max_val\n",
    "        quantized = [np.clip(round(x * scale), -128, 127) / scale for x in numbers]\n",
    "    \n",
    "    print(\"Quantized values:\", quantized)\n",
    "    \n",
    "    # Perform arithmetic operations\n",
    "    if len(quantized) >= 5:\n",
    "        a, b, c, d, e = quantized[:5]\n",
    "        \n",
    "        # Basic operations\n",
    "        add_result = a + c\n",
    "        mult_result = a * d\n",
    "        div_result = d / c if c != 0 else float('inf')\n",
    "        complex_result = (a + b) * c - e\n",
    "        \n",
    "        print(f\"a + c = {a} + {c} = {add_result}\")\n",
    "        print(f\"a * d = {a} * {d} = {mult_result}\")\n",
    "        print(f\"d / c = {d} / {c} = {div_result}\")\n",
    "        print(f\"(a + b) * c - e = {complex_result}\")\n",
    "        \n",
    "        return {\n",
    "            'quantized': quantized,\n",
    "            'add': add_result,\n",
    "            'mult': mult_result,\n",
    "            'div': div_result,\n",
    "            'complex': complex_result\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d15601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FLOAT32 Results:\n",
      "------------------------------\n",
      "Quantized values: [np.float32(2.3888888), np.float32(0.0), np.float32(34.444), np.float32(123486.0), np.float32(-1223.4565)]\n",
      "a + c = 2.3888888359069824 + 34.444000244140625 = 36.832889556884766\n",
      "a * d = 2.3888888359069824 * 123486.0 = 294994.3125\n",
      "d / c = 123486.0 / 34.444000244140625 = 3585.12353515625\n",
      "(a + b) * c - e = 1305.7393798828125\n",
      "\n",
      "FLOAT16 Results:\n",
      "------------------------------\n",
      "Quantized values: [np.float16(2.389), np.float16(0.0), np.float16(34.44), np.float16(inf), np.float16(-1223.0)]\n",
      "a + c = 2.388671875 + 34.4375 = 36.8125\n",
      "a * d = 2.388671875 * inf = inf\n",
      "d / c = inf / 34.4375 = inf\n",
      "(a + b) * c - e = 1305.0\n",
      "\n",
      "BFLOAT16 Results:\n",
      "------------------------------\n",
      "Quantized values: [np.float32(2.39), 0.0, np.float32(34.4), np.float32(123486.0), np.float32(-1223.0)]\n",
      "a + c = 2.390000104904175 + 34.400001525878906 = 36.790000915527344\n",
      "a * d = 2.390000104904175 * 123486.0 = 295131.5625\n",
      "d / c = 123486.0 / 34.400001525878906 = 3589.709228515625\n",
      "(a + b) * c - e = 1305.216064453125\n",
      "\n",
      "INT8 Results:\n",
      "------------------------------\n",
      "Quantized values: [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(123485.99999999999), np.float64(-972.3307086614172)]\n",
      "a + c = 0.0 + 0.0 = 0.0\n",
      "a * d = 0.0 * 123485.99999999999 = 0.0\n",
      "d / c = 123485.99999999999 / 0.0 = inf\n",
      "(a + b) * c - e = 972.3307086614172\n",
      "\n",
      "============================================================\n",
      "PRECISION LOSS COMPARISON\n",
      "============================================================\n",
      "\n",
      "FLOAT16 vs FLOAT32:\n",
      "-------------------------\n",
      "Value 1: 2.388889 → 2.388672 (error: 0.000217, 0.01%)\n",
      "Value 2: 0.000000 → 0.000000 (error: 0.000000, 0.00%)\n",
      "Value 3: 34.444000 → 34.437500 (error: 0.006500, 0.02%)\n",
      "Value 4: 123486.000000 → inf (error: inf, inf%)\n",
      "Value 5: -1223.456543 → -1223.000000 (error: 0.456543, 0.04%)\n",
      "\n",
      "Operation errors:\n",
      "add: 36.832890 → 36.812500 (error: 0.020390, 0.06%)\n",
      "mult: 294994.312500 → inf (error: inf, inf%)\n",
      "div: 3585.123535 → inf (error: inf, inf%)\n",
      "complex: 1305.739380 → 1305.000000 (error: 0.739380, 0.06%)\n",
      "\n",
      "BFLOAT16 vs FLOAT32:\n",
      "-------------------------\n",
      "Value 1: 2.388889 → 2.390000 (error: 0.001111, 0.05%)\n",
      "Value 2: 0.000000 → 0.000000 (error: 0.000000, 0.00%)\n",
      "Value 3: 34.444000 → 34.400002 (error: 0.043999, 0.13%)\n",
      "Value 4: 123486.000000 → 123486.000000 (error: 0.000000, 0.00%)\n",
      "Value 5: -1223.456543 → -1223.000000 (error: 0.456543, 0.04%)\n",
      "\n",
      "Operation errors:\n",
      "add: 36.832890 → 36.790001 (error: 0.042889, 0.12%)\n",
      "mult: 294994.312500 → 295131.562500 (error: 137.250000, 0.05%)\n",
      "div: 3585.123535 → 3589.709229 (error: 4.585693, 0.13%)\n",
      "complex: 1305.739380 → 1305.216064 (error: 0.523315, 0.04%)\n",
      "\n",
      "INT8 vs FLOAT32:\n",
      "-------------------------\n",
      "Value 1: 2.388889 → 0.000000 (error: 2.388889, 100.00%)\n",
      "Value 2: 0.000000 → 0.000000 (error: 0.000000, 0.00%)\n",
      "Value 3: 34.444000 → 0.000000 (error: 34.444000, 100.00%)\n",
      "Value 4: 123486.000000 → 123486.000000 (error: 0.000000, 0.00%)\n",
      "Value 5: -1223.456543 → -972.330709 (error: 251.125834, 20.53%)\n",
      "\n",
      "Operation errors:\n",
      "add: 36.832890 → 0.000000 (error: 36.832890, 100.00%)\n",
      "mult: 294994.312500 → 0.000000 (error: 294994.312500, 100.00%)\n",
      "div: 3585.123535 → inf (error: inf, inf%)\n",
      "complex: 1305.739380 → 972.330709 (error: 333.408671, 25.53%)\n",
      "\n",
      "============================================================\n",
      "SUMMARY:\n",
      "• Float32: Full precision baseline\n",
      "• Float16: ~3-4 decimal digits, can handle large ranges\n",
      "• BFloat16: ~3-4 decimal digits, better for large numbers\n",
      "• Int8: Severe quantization, only 256 possible values\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zyad3\\AppData\\Local\\Temp\\ipykernel_13576\\1725669987.py:8: RuntimeWarning: overflow encountered in cast\n",
      "  quantized = [np.float16(x) for x in numbers]\n"
     ]
    }
   ],
   "source": [
    "# Test all quantization levels\n",
    "results = {}\n",
    "for dtype in [\"float32\", \"float16\", \"bfloat16\", \"int8\"]:\n",
    "    results[dtype] = quantize_and_compute(numbers, dtype)\n",
    "\n",
    "# Compare precision loss\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRECISION LOSS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "original_float32 = results[\"float32\"]\n",
    "\n",
    "for dtype in [\"float16\", \"bfloat16\", \"int8\"]:\n",
    "    print(f\"\\n{dtype.upper()} vs FLOAT32:\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    # Compare quantized values\n",
    "    for i, (orig, quant) in enumerate(zip(numbers, results[dtype]['quantized'])):\n",
    "        orig_f32 = np.float32(orig)\n",
    "        error = abs(orig_f32 - quant)\n",
    "        rel_error = (error / abs(orig_f32) * 100) if orig_f32 != 0 else 0\n",
    "        print(f\"Value {i+1}: {orig_f32:.6f} → {quant:.6f} (error: {error:.6f}, {rel_error:.2f}%)\")\n",
    "    \n",
    "    # Compare operation results\n",
    "    print(\"\\nOperation errors:\")\n",
    "    for op in ['add', 'mult', 'div', 'complex']:\n",
    "        if op in original_float32 and op in results[dtype]:\n",
    "            orig_val = original_float32[op]\n",
    "            quant_val = results[dtype][op]\n",
    "            error = abs(orig_val - quant_val)\n",
    "            rel_error = (error / abs(orig_val) * 100) if orig_val != 0 and abs(orig_val) != float('inf') else 0\n",
    "            print(f\"{op}: {orig_val:.6f} → {quant_val:.6f} (error: {error:.6f}, {rel_error:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY:\")\n",
    "print(\"• Float32: Full precision baseline\")\n",
    "print(\"• Float16: ~3-4 decimal digits, can handle large ranges\")\n",
    "print(\"• BFloat16: ~3-4 decimal digits, better for large numbers\")\n",
    "print(\"• Int8: Severe quantization, only 256 possible values\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
