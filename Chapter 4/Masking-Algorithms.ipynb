{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e377468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, T5Tokenizer, T5ForConditionalGeneration\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b47d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskingStrategies:\n",
    "    def __init__(self, model_name=\"bert-base-uncased\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "        self.mask_token = self.tokenizer.mask_token\n",
    "        self.mask_token_id = self.tokenizer.mask_token_id\n",
    "        \n",
    "    def get_word_frequencies(self, texts):\n",
    "        word_counts = Counter()\n",
    "        for text in texts:\n",
    "            words = text.lower().split()\n",
    "            word_counts.update(words)\n",
    "        return word_counts\n",
    "    \n",
    "    def random_masking(self, text, mask_rate=0.15):\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        masked_tokens = tokens.copy()\n",
    "        \n",
    "        num_to_mask = int(len(tokens) * mask_rate)\n",
    "        mask_indices = random.sample(range(len(tokens)), min(num_to_mask, len(tokens)))\n",
    "        \n",
    "        for idx in mask_indices:\n",
    "            masked_tokens[idx] = self.mask_token\n",
    "            \n",
    "        return self.tokenizer.convert_tokens_to_string(masked_tokens)\n",
    "    \n",
    "    def frequency_based_masking(self, text, word_frequencies, mask_rate=0.15, mask_rare=True):\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        masked_tokens = tokens.copy()\n",
    "        \n",
    "        # Get frequency scores for each token\n",
    "        token_scores = []\n",
    "        for i, token in enumerate(tokens):\n",
    "            word = token.replace('##', '')  # Handle subword tokens\n",
    "            freq = word_frequencies.get(word.lower(), 1)\n",
    "            token_scores.append((i, freq))\n",
    "        \n",
    "        # Sort by frequency (ascending for rare words, descending for common)\n",
    "        if mask_rare:\n",
    "            token_scores.sort(key=lambda x: x[1])  # Mask rare words first\n",
    "        else:\n",
    "            token_scores.sort(key=lambda x: x[1], reverse=True)  # Mask common words first\n",
    "        \n",
    "        num_to_mask = int(len(tokens) * mask_rate)\n",
    "        mask_indices = [idx for idx, _ in token_scores[:num_to_mask]]\n",
    "        \n",
    "        for idx in mask_indices:\n",
    "            masked_tokens[idx] = self.mask_token\n",
    "            \n",
    "        return self.tokenizer.convert_tokens_to_string(masked_tokens)\n",
    "    \n",
    "    def pos_based_masking(self, text, mask_rate=0.15, prefer_content_words=True):\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        masked_tokens = tokens.copy()\n",
    "        \n",
    "        # Simple heuristic for content words (nouns, verbs, adjectives, adverbs)\n",
    "        content_word_patterns = [\n",
    "            r'\\w+ing$',  # gerunds/present participles\n",
    "            r'\\w+ed$',   # past tense verbs\n",
    "            r'\\w+ly$',   # adverbs\n",
    "            r'\\w+tion$', # nouns ending in -tion\n",
    "            r'\\w+ness$', # nouns ending in -ness\n",
    "        ]\n",
    "        \n",
    "        # Function words to avoid masking\n",
    "        function_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', \n",
    "                         'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were'}\n",
    "        \n",
    "        content_indices = []\n",
    "        function_indices = []\n",
    "        \n",
    "        for i, token in enumerate(tokens):\n",
    "            word = token.replace('##', '').lower()\n",
    "            \n",
    "            if word in function_words:\n",
    "                function_indices.append(i)\n",
    "            elif any(re.match(pattern, word) for pattern in content_word_patterns):\n",
    "                content_indices.append(i)\n",
    "            elif len(word) > 3:  # Longer words are likely content words\n",
    "                content_indices.append(i)\n",
    "            else:\n",
    "                function_indices.append(i)\n",
    "        \n",
    "        num_to_mask = int(len(tokens) * mask_rate)\n",
    "        \n",
    "        if prefer_content_words and content_indices:\n",
    "            # Prioritize content words\n",
    "            available_indices = content_indices + function_indices\n",
    "            mask_indices = available_indices[:num_to_mask]\n",
    "        else:\n",
    "            # Random selection\n",
    "            mask_indices = random.sample(range(len(tokens)), min(num_to_mask, len(tokens)))\n",
    "        \n",
    "        for idx in mask_indices:\n",
    "            masked_tokens[idx] = self.mask_token\n",
    "            \n",
    "        return self.tokenizer.convert_tokens_to_string(masked_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592f1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5MaskingStrategies:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    \n",
    "    def span_masking(self, text, mask_rate=0.15, avg_span_length=3):\n",
    "        tokens = text.split()\n",
    "        masked_text = \"\"\n",
    "        targets = \"\"\n",
    "        \n",
    "        i = 0\n",
    "        mask_id = 0\n",
    "        \n",
    "        while i < len(tokens):\n",
    "            if random.random() < mask_rate:\n",
    "                # Start a masked span\n",
    "                span_length = np.random.poisson(avg_span_length) + 1\n",
    "                span_length = min(span_length, len(tokens) - i)\n",
    "                \n",
    "                # Add mask token to input\n",
    "                mask_token = f\"<extra_id_{mask_id}>\"\n",
    "                masked_text += mask_token + \" \"\n",
    "                \n",
    "                # Add original tokens to target\n",
    "                targets += mask_token + \" \"\n",
    "                for j in range(span_length):\n",
    "                    if i + j < len(tokens):\n",
    "                        targets += tokens[i + j] + \" \"\n",
    "                \n",
    "                i += span_length\n",
    "                mask_id += 1\n",
    "            else:\n",
    "                masked_text += tokens[i] + \" \"\n",
    "                i += 1\n",
    "        \n",
    "        targets += f\"<extra_id_{mask_id}>\"\n",
    "        \n",
    "        return masked_text.strip(), targets.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c781640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_masking_strategies():\n",
    "    \n",
    "    # Sample texts\n",
    "    texts = [\n",
    "        \"The quick brown fox jumps over the lazy dog in the beautiful garden.\",\n",
    "        \"Machine learning algorithms require substantial computational resources for training.\",\n",
    "        \"Climate change affects global weather patterns and ocean temperatures significantly.\",\n",
    "        \"Artificial intelligence revolutionizes healthcare through predictive analytics and automation.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"MASKING STRATEGIES DEMONSTRATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Initialize masking strategies\n",
    "    mlm_masker = MaskingStrategies(\"bert-base-uncased\")\n",
    "    t5_masker = T5MaskingStrategies()\n",
    "    \n",
    "    # Calculate word frequencies for intelligent masking\n",
    "    word_frequencies = mlm_masker.get_word_frequencies(texts)\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        print(f\"\\n--- EXAMPLE {i+1} ---\")\n",
    "        print(f\"Original: {text}\")\n",
    "        print()\n",
    "        \n",
    "        # Test different masking rates\n",
    "        mask_rates = [0.15, 0.30, 0.50]\n",
    "        \n",
    "        for rate in mask_rates:\n",
    "            print(f\"MASKING RATE: {rate:.0%}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # 1. MLM - Random Masking\n",
    "            random_masked = mlm_masker.random_masking(text, mask_rate=rate)\n",
    "            print(f\"MLM Random:     {random_masked}\")\n",
    "            \n",
    "            # 2. MLM - Frequency-based (rare words)\n",
    "            freq_rare_masked = mlm_masker.frequency_based_masking(\n",
    "                text, word_frequencies, mask_rate=rate, mask_rare=True\n",
    "            )\n",
    "            print(f\"MLM Rare Words: {freq_rare_masked}\")\n",
    "            \n",
    "            # 3. MLM - POS-based (content words)\n",
    "            pos_masked = mlm_masker.pos_based_masking(text, mask_rate=rate)\n",
    "            print(f\"MLM Content:    {pos_masked}\")\n",
    "            \n",
    "            # 4. PLM/T5 - Span masking\n",
    "            if rate <= 0.30:  # T5 works better with lower masking rates\n",
    "                span_input, span_target = t5_masker.span_masking(text, mask_rate=rate)\n",
    "                print(f\"PLM Input:      {span_input}\")\n",
    "                print(f\"PLM Target:     {span_target}\")\n",
    "            \n",
    "            print()\n",
    "    \n",
    "    # Demonstrate advanced masking heuristics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ADVANCED MASKING HEURISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    sample_text = \"The artificial intelligence system processes natural language with remarkable accuracy.\"\n",
    "    \n",
    "    print(f\"Original: {sample_text}\")\n",
    "    print()\n",
    "    \n",
    "    # Different intelligent masking strategies\n",
    "    strategies = [\n",
    "        (\"Random\", lambda: mlm_masker.random_masking(sample_text, 0.25)),\n",
    "        (\"Rare Words\", lambda: mlm_masker.frequency_based_masking(\n",
    "            sample_text, word_frequencies, 0.25, mask_rare=True)),\n",
    "        (\"Common Words\", lambda: mlm_masker.frequency_based_masking(\n",
    "            sample_text, word_frequencies, 0.25, mask_rare=False)),\n",
    "        (\"Content Words\", lambda: mlm_masker.pos_based_masking(\n",
    "            sample_text, 0.25, prefer_content_words=True)),\n",
    "        (\"Function Words\", lambda: mlm_masker.pos_based_masking(\n",
    "            sample_text, 0.25, prefer_content_words=False)),\n",
    "    ]\n",
    "    \n",
    "    for name, strategy in strategies:\n",
    "        result = strategy()\n",
    "        print(f\"{name:15}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda6ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_example():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TRAINING EXAMPLE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    masker = MaskingStrategies(\"bert-base-uncased\")\n",
    "    \n",
    "    # Sample training data\n",
    "    training_text = \"Machine learning models learn patterns from large datasets.\"\n",
    "    \n",
    "    # Create masked input\n",
    "    masked_text = masker.random_masking(training_text, mask_rate=0.15)\n",
    "    \n",
    "    # Tokenize for model input\n",
    "    inputs = masker.tokenizer(masked_text, return_tensors=\"pt\", padding=True)\n",
    "    labels = masker.tokenizer(training_text, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    print(f\"Original text: {training_text}\")\n",
    "    print(f\"Masked text:   {masked_text}\")\n",
    "    print(f\"Input IDs:     {inputs['input_ids']}\")\n",
    "    print(f\"Labels:        {labels['input_ids']}\")\n",
    "    \n",
    "    # For T5 (PLM example)\n",
    "    print(\"\\nT5 (PLM) Example:\")\n",
    "    t5_masker = T5MaskingStrategies()\n",
    "    span_input, span_target = t5_masker.span_masking(training_text, mask_rate=0.20)\n",
    "    \n",
    "    input_ids = t5_masker.tokenizer(span_input, return_tensors=\"pt\").input_ids\n",
    "    target_ids = t5_masker.tokenizer(span_target, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    print(f\"T5 Input:      {span_input}\")\n",
    "    print(f\"T5 Target:     {span_target}\")\n",
    "    print(f\"Input IDs:     {input_ids}\")\n",
    "    print(f\"Target IDs:    {target_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de3ff3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MASKING STRATEGIES DEMONSTRATION\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f92e664971146aeaa031b72dc285584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zyad3\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\zyad3\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bd9e874d944f13bb80aba63e873e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04074d8759a4e86ae9acd07a1b1153c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747417399d194250b12142ba3a3ea536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70019de2bf964dc2b7e9868313e86396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e0235059f54cad96be1c6e233a557c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- EXAMPLE 1 ---\n",
      "Original: The quick brown fox jumps over the lazy dog in the beautiful garden.\n",
      "\n",
      "MASKING RATE: 15%\n",
      "----------------------------------------\n",
      "MLM Random:     the [MASK] brown fox jumps over the lazy dog in [MASK] beautiful garden.\n",
      "MLM Rare Words: the [MASK] [MASK] fox jumps over the lazy dog in the beautiful garden.\n",
      "MLM Content:    the [MASK] [MASK] fox jumps over the lazy dog in the beautiful garden.\n",
      "PLM Input:      <extra_id_0> over the lazy dog in <extra_id_1> garden.\n",
      "PLM Target:     <extra_id_0> The quick brown fox jumps <extra_id_1> the beautiful <extra_id_2>\n",
      "\n",
      "MASKING RATE: 30%\n",
      "----------------------------------------\n",
      "MLM Random:     [MASK] [MASK] brown [MASK] jumps over the lazy dog in the [MASK] garden.\n",
      "MLM Rare Words: the [MASK] [MASK] [MASK] [MASK] over the lazy dog in the beautiful garden.\n",
      "MLM Content:    the [MASK] [MASK] fox [MASK] [MASK] the lazy dog in the beautiful garden.\n",
      "PLM Input:      The <extra_id_0> <extra_id_1> in the <extra_id_2>\n",
      "PLM Target:     <extra_id_0> quick brown fox jumps <extra_id_1> over the lazy dog <extra_id_2> beautiful garden. <extra_id_3>\n",
      "\n",
      "MASKING RATE: 50%\n",
      "----------------------------------------\n",
      "MLM Random:     [MASK] quick [MASK] fox [MASK] [MASK] [MASK] lazy dog [MASK] the beautiful [MASK].\n",
      "MLM Rare Words: the [MASK] [MASK] [MASK] [MASK] [MASK] the [MASK] [MASK] in the beautiful garden.\n",
      "MLM Content:    the [MASK] [MASK] fox [MASK] [MASK] the [MASK] dog in the [MASK] [MASK].\n",
      "\n",
      "\n",
      "--- EXAMPLE 2 ---\n",
      "Original: Machine learning algorithms require substantial computational resources for training.\n",
      "\n",
      "MASKING RATE: 15%\n",
      "----------------------------------------\n",
      "MLM Random:     machine learning [MASK] require substantial computational resources for training.\n",
      "MLM Rare Words: [MASK] learning algorithms require substantial computational resources for training.\n",
      "MLM Content:    [MASK] learning algorithms require substantial computational resources for training.\n",
      "PLM Input:      Machine learning <extra_id_0> resources for training.\n",
      "PLM Target:     <extra_id_0> algorithms require substantial computational <extra_id_1>\n",
      "\n",
      "MASKING RATE: 30%\n",
      "----------------------------------------\n",
      "MLM Random:     [MASK] learning algorithms require [MASK] computational resources [MASK] training.\n",
      "MLM Rare Words: [MASK] [MASK] [MASK] require substantial computational resources for training.\n",
      "MLM Content:    [MASK] [MASK] [MASK] require substantial computational resources for training.\n",
      "PLM Input:      Machine learning algorithms require substantial computational resources for training.\n",
      "PLM Target:     <extra_id_0>\n",
      "\n",
      "MASKING RATE: 50%\n",
      "----------------------------------------\n",
      "MLM Random:     [MASK] [MASK] algorithms [MASK] [MASK] computational resources for training [MASK]\n",
      "MLM Rare Words: [MASK] [MASK] [MASK] [MASK] [MASK] computational resources for training.\n",
      "MLM Content:    [MASK] [MASK] [MASK] [MASK] [MASK] computational resources for training.\n",
      "\n",
      "\n",
      "--- EXAMPLE 3 ---\n",
      "Original: Climate change affects global weather patterns and ocean temperatures significantly.\n",
      "\n",
      "MASKING RATE: 15%\n",
      "----------------------------------------\n",
      "MLM Random:     climate [MASK] affects global weather patterns and ocean temperatures significantly.\n",
      "MLM Rare Words: [MASK] change affects global weather patterns and ocean temperatures significantly.\n",
      "MLM Content:    [MASK] change affects global weather patterns and ocean temperatures significantly.\n",
      "PLM Input:      Climate change affects global weather patterns and ocean <extra_id_0>\n",
      "PLM Target:     <extra_id_0> temperatures significantly. <extra_id_1>\n",
      "\n",
      "MASKING RATE: 30%\n",
      "----------------------------------------\n",
      "MLM Random:     climate change [MASK] global weather patterns and ocean [MASK] significantly [MASK]\n",
      "MLM Rare Words: [MASK] [MASK] [MASK] global weather patterns and ocean temperatures significantly.\n",
      "MLM Content:    [MASK] [MASK] [MASK] global weather patterns and ocean temperatures significantly.\n",
      "PLM Input:      Climate <extra_id_0> patterns and ocean temperatures significantly.\n",
      "PLM Target:     <extra_id_0> change affects global weather <extra_id_1>\n",
      "\n",
      "MASKING RATE: 50%\n",
      "----------------------------------------\n",
      "MLM Random:     [MASK] change affects [MASK] weather [MASK] and ocean temperatures [MASK] [MASK]\n",
      "MLM Rare Words: [MASK] [MASK] [MASK] [MASK] [MASK] patterns and ocean temperatures significantly.\n",
      "MLM Content:    [MASK] [MASK] [MASK] [MASK] [MASK] patterns and ocean temperatures significantly.\n",
      "\n",
      "\n",
      "--- EXAMPLE 4 ---\n",
      "Original: Artificial intelligence revolutionizes healthcare through predictive analytics and automation.\n",
      "\n",
      "MASKING RATE: 15%\n",
      "----------------------------------------\n",
      "MLM Random:     artificial intelligence revolutionizes [MASK] through predictive analytics and automation.\n",
      "MLM Rare Words: [MASK] intelligence revolutionizes healthcare through predictive analytics and automation.\n",
      "MLM Content:    [MASK] intelligence revolutionizes healthcare through predictive analytics and automation.\n",
      "PLM Input:      <extra_id_0> intelligence revolutionizes healthcare through predictive analytics and <extra_id_1>\n",
      "PLM Target:     <extra_id_0> Artificial <extra_id_1> automation. <extra_id_2>\n",
      "\n",
      "MASKING RATE: 30%\n",
      "----------------------------------------\n",
      "MLM Random:     artificial intelligence [MASK] [MASK] healthcare through predictive [MASK] and automation.\n",
      "MLM Rare Words: [MASK] [MASK] [MASK]izes healthcare through predictive analytics and automation.\n",
      "MLM Content:    [MASK] [MASK] [MASK]izes healthcare through predictive analytics and automation.\n",
      "PLM Input:      Artificial intelligence revolutionizes healthcare through predictive <extra_id_0>\n",
      "PLM Target:     <extra_id_0> analytics and automation. <extra_id_1>\n",
      "\n",
      "MASKING RATE: 50%\n",
      "----------------------------------------\n",
      "MLM Random:     [MASK] [MASK] [MASK]izes healthcare [MASK] predict [MASK] analytics and [MASK].\n",
      "MLM Rare Words: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] predictive analytics and automation.\n",
      "MLM Content:    [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] predictive analytics and automation.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ADVANCED MASKING HEURISTICS\n",
      "================================================================================\n",
      "Original: The artificial intelligence system processes natural language with remarkable accuracy.\n",
      "\n",
      "Random         : the artificial [MASK] system processes natural [MASK] with remarkable accuracy.\n",
      "Rare Words     : the [MASK] [MASK] system processes natural language with remarkable accuracy.\n",
      "Common Words   : [MASK] [MASK] intelligence system processes natural language with remarkable accuracy.\n",
      "Content Words  : the [MASK] [MASK] system processes natural language with remarkable accuracy.\n",
      "Function Words : the [MASK] intelligence system processes natural language with remarkable [MASK].\n",
      "\n",
      "================================================================================\n",
      "TRAINING EXAMPLE\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Machine learning models learn patterns from large datasets.\n",
      "Masked text:   machine learning models learn patterns from [MASK] datasets.\n",
      "Input IDs:     tensor([[  101,  3698,  4083,  4275,  4553,  7060,  2013,   103,  2951, 13462,\n",
      "          2015,  1012,   102]])\n",
      "Labels:        tensor([[  101,  3698,  4083,  4275,  4553,  7060,  2013,  2312,  2951, 13462,\n",
      "          2015,  1012,   102]])\n",
      "\n",
      "T5 (PLM) Example:\n",
      "T5 Input:      Machine learning models learn patterns <extra_id_0>\n",
      "T5 Target:     <extra_id_0> from large datasets. <extra_id_1>\n",
      "Input IDs:     tensor([[ 5879,  1036,  2250,   669,  4264, 32099,     1]])\n",
      "Target IDs:    tensor([[32099,    45,   508, 17953,     7,     5, 32098,     1]])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    demonstrate_masking_strategies()\n",
    "    training_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f033ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
